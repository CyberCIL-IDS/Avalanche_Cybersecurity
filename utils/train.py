# utils/train.py (o train.py)

import torch
from avalanche.training.strategies import Replay
from avalanche.training.plugins import EvaluationPlugin
from avalanche.evaluation.metrics import accuracy_metrics, loss_metrics
from avalanche.logging import InteractiveLogger

from model import NeuralNetwork       # <-- usa il tuo modello
from benchmark import get_benchmark   # <-- benchmark giÃ  preprocessato e pronto


def train():

    # 1ï¸âƒ£ Carica il benchmark (giÃ  preprocessato dai tuoi script)
    benchmark = get_benchmark()

    # 2ï¸âƒ£ Istanzia il modello
    model = NeuralNetwork()

    # 3ï¸âƒ£ Imposta ottimizzatore
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

    # 4ï¸âƒ£ Plugin per logging ed evaluation
    eval_plugin = EvaluationPlugin(
        accuracy_metrics(epoch=True, experience=True, stream=True),
        loss_metrics(epoch=True, experience=True, stream=True),
        loggers=[InteractiveLogger()]
    )

    # 5ï¸âƒ£ Strategy Replay â€” continual learning con memory buffer
    strategy = Replay(
        model=model,
        optimizer=optimizer,
        criterion=torch.nn.CrossEntropyLoss(),
        train_mb_size=64,
        train_epochs=5,
        eval_mb_size=64,
        evaluator=eval_plugin,
        device="cuda" if torch.cuda.is_available() else "cpu",
        mem_size=2000   # buffer di replay
    )

    # 6ï¸âƒ£ Training sulle esperienze incrementali
    for experience in benchmark.train_stream:
        print(f"\nâ–¶ï¸ Training su: {experience}")
        strategy.train(experience)

        print("\nðŸ“Š Evaluation:")
        strategy.eval(benchmark.test_stream)

    print("\nâœ… Training completato con Replay Strategy + NeuralNetwork.")


if __name__ == "__main__":
    train()
